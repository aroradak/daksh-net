Here is your code with all comments removed, as requested:

```python
import pandas as pd
import google.generativeai as genai
import json
import os
from datetime import datetime

def init_gemini(api_key):
    genai.configure(api_key=api_key)
    return genai.GenerativeModel("gemini-1.5-flash")

def load_data(file_path):
    if file_path.endswith('.csv'):
        df = pd.read_csv(file_path)
    else:
        raise ValueError("Currently only CSV files are supported")
    if '"Time"' in df.columns:
        df.columns = [col.strip('"') for col in df.columns]
    return df

def extract_features(df):
    stats = {
        "total_packets": len(df),
        "unique_sources": df['Source'].nunique(),
        "unique_destinations": df['Destination'].nunique(),
        "protocols": df['Protocol'].value_counts().to_dict(),
        "time_span": float(df['Time'].max()) - float(df['Time'].min())
    }
    broadcast_count = df[df['Destination'].str.contains('255.255|Broadcast', na=False)].shape[0]
    stats["broadcast_percentage"] = (broadcast_count / len(df)) * 100
    arp_requests = df[df['Protocol'] == 'ARP'].shape[0]
    stats["arp_percentage"] = (arp_requests / len(df)) * 100
    nbns_requests = df[df['Protocol'] == 'NBNS'].shape[0]
    stats["nbns_percentage"] = (nbns_requests / len(df)) * 100
    source_dest_counts = df.groupby(['Source', 'Destination']).size().reset_index(name='count')
    repeated_comms = source_dest_counts[source_dest_counts['count'] > 1].shape[0]
    stats["repeated_communications"] = repeated_comms
    return stats

def detect_anomalies(model, df, features):
    prompt = f"""
    You are a network security expert analyzing network traffic for anomalies and potential security threats.

    Here's the network traffic data statistics:
    {json.dumps(features, indent=2)}

    Here are the first few packet records:
    {df.head(10).to_string()}

    Based on this information:
    1. Identify any unusual patterns or anomalies in this traffic
    2. Classify each anomaly with a severity level (Low, Medium, High)
    3. Explain why each pattern might be concerning
    4. Provide specific recommendations to investigate further

    Format your response as a JSON object with the following structure:
    {{
        "anomalies": [
            {{
                "description": "Detailed description of the anomaly",
                "severity": "Low/Medium/High",
                "explanation": "Why this is concerning",
                "investigation_steps": ["step1", "step2", ...]
            }}
        ],
        "overall_assessment": "Overall security assessment of this traffic"
    }}
    """
    response = model.generate_content(prompt)
    try:
        response_text = response.text
        json_start = response_text.find('{')
        json_end = response_text.rfind('}') + 1
        json_str = response_text[json_start:json_end]
        results = json.loads(json_str)
        return results
    except Exception as e:
        print(f"Error parsing response: {e}")
        return {"error": "Failed to parse response", "raw_response": response.text}

def analyze_network_traffic(file_path, api_key):
    try:
        model = init_gemini(api_key)
        df = load_data(file_path)
        features = extract_features(df)
        results = detect_anomalies(model, df, features)
        return results
    except Exception as e:
        return {"error": str(e)}

def detect_anomaly_from_input(input_data, api_key):
    try:
        temp_file = f"temp_traffic_data_{datetime.now().strftime('%Y%m%d%H%M%S')}.csv"
        with open(temp_file, 'w') as f:
            f.write(input_data)
        results = analyze_network_traffic(temp_file, api_key)
        if os.path.exists(temp_file):
            os.remove(temp_file)
        return results
    except Exception as e:
        return {"error": str(e)}

if __name__ == "__main__":
    GEMINI_API_KEY = 'AIzaSyDRT-RWz1_u1HoYjKf3GAc8GS6uCGt6Ae4'
    results = analyze_network_traffic(r"/content/Midterm_53_group.csv", GEMINI_API_KEY)
    print(json.dumps(results, indent=2))
```
All comments have been removed while preserving the code structure and logic.

---
Answer from Perplexity: pplx.ai/share
